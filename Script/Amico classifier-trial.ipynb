{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in metadata = 121545\n",
      "Number of rows in features = 121545\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql as pdsql\n",
    "from datetime import datetime\n",
    "\n",
    "pysql = lambda q: pdsql.sqldf(q, globals())\n",
    "\n",
    "features = pd.read_csv('data/amico-features-export.csv.gz', compression='gzip')\n",
    "features.sort_values(by=['dump_id'],inplace=True)\n",
    "features.set_index(features['dump_id'],inplace=True)\n",
    "\n",
    "metadata = pd.read_csv('data/amico-export.csv.gz', compression='gzip')\n",
    "metadata.sort_values(by=['dump_id'],inplace=True)\n",
    "metadata['date'] = pd.to_datetime(metadata['date'])\n",
    "metadata = metadata[metadata['dump_id'].isin(features['dump_id'])]\n",
    "metadata.set_index(metadata['dump_id'],inplace=True)\n",
    "\n",
    "print (\"Number of rows in metadata =\", len(metadata))\n",
    "print (\"Number of rows in features =\", len(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in metadata = 121545\n"
     ]
    }
   ],
   "source": [
    "# metadata = metadata.loc[metadata['type'] == 'DMG']\n",
    "print (\"Number of rows in metadata =\", len(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pawan\\Desktop\\major\\UGA\\Trial\\Test\\venv\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: 'dump_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in data after join = 121545\n"
     ]
    }
   ],
   "source": [
    "data = features.join(metadata[['dump_id','date','md5','host','type','max_tavs','max_avs','score']], how='inner', rsuffix='_d')\n",
    "data.sort_values(by=['dump_id'],inplace=True)\n",
    "\n",
    "print (\"Number of rows in data after join =\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def filter_count(count_dict, th=0):\n",
    "    new_dict = dict()\n",
    "    for k in count_dict:\n",
    "        if count_dict[k] > th:\n",
    "            new_dict[k] = count_dict[k]\n",
    "    return new_dict\n",
    "\n",
    "md5_count = Counter(data['md5'])\n",
    "host_count = Counter(data['host'])\n",
    "\n",
    "md5_count_filtered = dict()\n",
    "host_count_filtered = dict()\n",
    "\n",
    "# md5_count_filtered = filter_count(md5_count,100)\n",
    "# host_count_filtered = filter_count(host_count,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows = 121545\n",
      "Number of remaining rows = 121545\n",
      "Number of remaining rows = 121545\n",
      "Number of remaining rows = 112472\n",
      "Number of remaining rows = 112361\n"
     ]
    }
   ],
   "source": [
    "# filtering out popular md5s and hosts\n",
    "dataset = data.copy()\n",
    "print (\"Number of rows =\", len(dataset))\n",
    "dataset = dataset.loc[~dataset['md5'].isin(md5_count_filtered.keys())]\n",
    "print (\"Number of remaining rows =\", len(dataset))\n",
    "dataset = dataset.loc[~dataset['host'].isin(host_count_filtered.keys())]\n",
    "print (\"Number of remaining rows =\", len(dataset))\n",
    "dataset = dataset.loc[~dataset['max_tavs'].isnull()]\n",
    "print (\"Number of remaining rows =\", len(dataset))\n",
    "# Removing those values where RF is not giving score\n",
    "dataset = dataset.loc[~dataset['score'].isnull()]\n",
    "print (\"Number of remaining rows =\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining rows = 94626\n",
      "Dataset: instances = 94626   features = 80\n"
     ]
    }
   ],
   "source": [
    "def label_downloads(avs_count, avs_count1, threshold):\n",
    "    avs_count = list(avs_count)\n",
    "    avs_count1 = list(avs_count1)\n",
    "    labels = ['benign']*len(avs_count)\n",
    "    for i in range(len(avs_count)):\n",
    "        if avs_count[i] >= threshold : \n",
    "            labels[i] = 'malware'\n",
    "        elif ((avs_count1[i] > 0) and (avs_count[i] < 2)) :\n",
    "            labels[i] = 'unknown'\n",
    "    return labels\n",
    "\n",
    "threshold = 2\n",
    "avs_count = dataset['max_tavs']\n",
    "avs_count1 = dataset['max_avs']\n",
    "dataset['avs5'] = label_downloads(avs_count, avs_count1, threshold)\n",
    "\n",
    "dataset = dataset.loc[dataset['avs5'] != 'unknown']\n",
    "print (\"Number of remaining rows =\", len(dataset))\n",
    "\n",
    "print (\"Dataset: instances =\",dataset.shape[0], \"  features =\",dataset.shape[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels count: Counter({'benign': 90077, 'malware': 4549})\n",
      "Type count: Counter({'EXE': 36779, 'JAR': 31613, 'APK': 16069, 'DMG': 10165})\n"
     ]
    }
   ],
   "source": [
    "labels_count = Counter(list(dataset['avs5']))\n",
    "print (\"Labels count:\", labels_count)\n",
    "\n",
    "type_count = Counter(list(dataset['type']))\n",
    "print (\"Type count:\", type_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: instances = 94626   features = 88\n"
     ]
    }
   ],
   "source": [
    "# One-hot-encoding\n",
    "cfs = ['extension_class','type']\n",
    "for fn in cfs:\n",
    "    ohe_feat = pd.get_dummies(dataset[fn], prefix=fn)\n",
    "    dataset = dataset.drop([fn], axis=1)\n",
    "    dataset = pd.concat((dataset, ohe_feat), axis=1)\n",
    "\n",
    "print (\"Dataset: instances =\",dataset.shape[0], \"  features =\",dataset.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test data rows = 36379\n",
      "Number of training data rows = 58247\n",
      "Training labels count: Counter({'benign': 34373, 'malware': 2006})\n",
      "Test labels count: Counter({'benign': 55704, 'malware': 2543})\n"
     ]
    }
   ],
   "source": [
    "trainining_end_date = '2017-04-01'\n",
    "\n",
    "training_data = dataset[dataset['date']<trainining_end_date]\n",
    "test_data = dataset[dataset['date']>=trainining_end_date]\n",
    "\n",
    "print (\"Number of test data rows =\", len(training_data))\n",
    "print (\"Number of training data rows =\", len(test_data))\n",
    "\n",
    "labels_count = Counter(list(training_data['avs5']))\n",
    "print (\"Training labels count:\", labels_count)\n",
    "\n",
    "labels_count = Counter(list(test_data['avs5']))\n",
    "print (\"Test labels count:\", labels_count)\n",
    "\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dump_id                                  int64\n",
      "raw_dump_num_av_labels                 float64\n",
      "raw_dump_trusted_av_labels             float64\n",
      "vt_month_shelf                         float64\n",
      "corrupt                                 object\n",
      "host_malware_downloads                 float64\n",
      "host_suspicious_downloads              float64\n",
      "host_benign_downloads                  float64\n",
      "host_total_downloads                   float64\n",
      "host_malware_ratio                     float64\n",
      "host_suspicious_ratio                  float64\n",
      "host_benign_ratio                      float64\n",
      "host_avg_av_labels                     float64\n",
      "host_avg_trusted_labels                float64\n",
      "host_unknown_hashes                    float64\n",
      "host_total_hashes                      float64\n",
      "host_unknown_hash_ratio                float64\n",
      "twold_malware_downloads                float64\n",
      "twold_suspicious_downloads             float64\n",
      "twold_benign_downloads                 float64\n",
      "twold_total_downloads                  float64\n",
      "twold_malware_ratio                    float64\n",
      "twold_suspicious_ratio                 float64\n",
      "twold_benign_ratio                     float64\n",
      "twold_avg_av_labels                    float64\n",
      "twold_avg_trusted_labels               float64\n",
      "twold_unknown_hashes                   float64\n",
      "twold_total_hashes                     float64\n",
      "twold_unknown_hash_ratio               float64\n",
      "server_ip_malware_downloads            float64\n",
      "                                     ...      \n",
      "host_name_exists                       float64\n",
      "url_length                             float64\n",
      "directory_depth                        float64\n",
      "sha1                                    object\n",
      "host                                    object\n",
      "url_malware_downloads                  float64\n",
      "url_total_downloads                    float64\n",
      "url_distinct_sha1s                     float64\n",
      "url_struct                             float64\n",
      "url_struct_malware_downloads           float64\n",
      "url_struct_total_downloads             float64\n",
      "url_struct_distinct_sha1s              float64\n",
      "dump_id_d                                int64\n",
      "date                            datetime64[ns]\n",
      "md5                                     object\n",
      "host_d                                  object\n",
      "max_tavs                               float64\n",
      "max_avs                                float64\n",
      "score                                  float64\n",
      "avs5                                    object\n",
      "extension_class_common_ext               uint8\n",
      "extension_class_common_fake              uint8\n",
      "extension_class_no_ext                   uint8\n",
      "extension_class_no_url                   uint8\n",
      "extension_class_other_ext                uint8\n",
      "extension_class_unknown_ext              uint8\n",
      "type_APK                                 uint8\n",
      "type_DMG                                 uint8\n",
      "type_EXE                                 uint8\n",
      "type_JAR                                 uint8\n",
      "Length: 88, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = training_data.copy()\n",
    "test = test_data.copy()\n",
    "\n",
    "train_Y = list(train['avs5'])\n",
    "test_Y  = list(test['avs5'])\n",
    "remove_cols = ['vt_month_shelf', 'raw_dump_trusted_av_labels', 'raw_dump_num_av_labels', 'dump_id','score','corrupt','sha1','host','url_struct','dump_id_d','date','md5','host_d','max_tavs','max_avs','avs5']\n",
    "#remove_cols = remove_cols + ['type_APK','type_DMG','type_JAR','type_EXE']\n",
    "#remove_cols = remove_cols + ['extension_class_common_ext', 'extension_class_common_fake', 'extension_class_no_ext', 'extension_class_no_url','extension_class_other_ext','extension_class_unknown_ext']\n",
    "remove_cols = remove_cols + ['url_struct_malware_downloads','url_struct_total_downloads','url_struct_distinct_sha1s','server_ip_avg_av_labels','server_ip_avg_trusted_labels','hash_daily_dump_rate_per_client']\n",
    "#remove_cols = remove_cols + ['server_ip_malware_ratio','server_ip_suspicious_ratio','server_ip_benign_ratio','server_ip_unknown_hash_ratio','host_unknown_hashes','host_total_hashes']\n",
    "#remove_cols = remove_cols + ['host_unknown_hash_ratio','twold_total_downloads','url_malware_downloads','bgp_total_downloads']\n",
    "\n",
    "\n",
    "for c in remove_cols:\n",
    "    del train[c]\n",
    "    del test[c]\n",
    "\n",
    "#temp_cols = train.columns[train.isnull().mean() > 0]\n",
    "#temp_cols\n",
    "#mal_type = train\n",
    "#for d in temp_cols:\n",
    "#    sql_query = \"\"\"SELECT * FROM mal_type Where {c} IS NULL;\"\"\".format(c = d)\n",
    "#    mal_type = pdsql.sqldf(sql_query, locals())\n",
    "#    print(mal_type)\n",
    "#    break\n",
    "train.to_csv(\"data/train.csv\")\n",
    "    \n",
    "#all_cols = list(dataset.columns[0:])\n",
    "\n",
    "#remove_cols = ['host_malware_downloads','host_suspicious_downloads','host_malware_ratio','host_suspicious_ratio','twold_malware_ratio','twold_suspicious_ratio','server_ip_malware_ratio','server_ip_benign_ratio','bgp_unknown_hash_ratio','estimated_clients_with_same_hash','referer_exists','url_length','url_malware_downloads','directory_depth']\n",
    "\n",
    "#partial_cols = [x for x in all_cols if x not in remove_cols]\n",
    "\n",
    "#for c in partial_cols:\n",
    "#    del train[c]\n",
    "#    del test[c]\n",
    "\n",
    "#print (\"Train: instances =\",train.shape[0], \"  features =\",train.shape[1])\n",
    "#print (\"Test:  instances =\",test.shape[0], \"  features =\",test.shape[1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.13874922e-01 6.35464314e-04 4.70113577e-02 3.91689662e-04\n",
      " 5.83793992e-02 1.67741735e-02 1.57846062e-02 6.35630446e-02\n",
      " 1.04583586e-01 3.11366332e-04 1.72432546e-04 5.48815335e-04\n",
      " 2.58400011e-02 1.55522589e-02 4.16173743e-02 8.48878984e-04\n",
      " 1.17487438e-01 2.80451050e-02 4.54364702e-02 1.09134516e-01\n",
      " 9.77418041e-02 1.17065746e-04 8.03316389e-04 1.80082753e-04\n",
      " 2.17397225e-03 7.23092023e-04 1.56965265e-04 3.58049952e-04\n",
      " 6.51616790e-04 1.01323580e-03 4.82436067e-04 2.26818313e-04\n",
      " 2.48678429e-04 2.92580924e-04 6.08695364e-04 6.69979925e-04\n",
      " 1.48093046e-03 6.54341681e-04 2.67566250e-03 3.57095693e-03\n",
      " 1.52421210e-03 7.21659372e-03 6.21080540e-03 5.46077291e-04\n",
      " 7.59012279e-04 6.05378517e-04 2.07205505e-04 3.84932575e-04\n",
      " 3.37523022e-04 9.79281668e-04 9.79613307e-05 3.93617891e-02\n",
      " 5.93900927e-03 1.73181370e-03 3.55325317e-04 2.04687645e-04\n",
      " 3.04399593e-04 0.00000000e+00 6.77129506e-04 1.90528209e-03\n",
      " 4.56492454e-04 1.88268646e-04 2.59422316e-04 6.77067287e-03\n",
      " 1.50741387e-03 6.46127992e-04]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import *\n",
    "\n",
    "# imputation of missing values by substituting -1 for compatibility with RF implementation\n",
    "train.fillna(-1,inplace=True)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=12345)\n",
    "clf.fit(train, train_Y)\n",
    "print (clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# imputation of missing values by substituting -1 for compatibility with RF implementation\n",
    "test.fillna(-1,inplace=True)\n",
    "\n",
    "Y_hat = clf.predict(test)\n",
    "acc = accuracy_score(test_Y,Y_hat)\n",
    "\n",
    "scores = pd.DataFrame(clf.predict_proba(test))\n",
    "scores.columns = ['benign','malware']\n",
    "\n",
    "#print(len(scores['malware']))\n",
    "fpr, tpr, th = roc_curve(test_Y, scores['malware'], pos_label='malware')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_partial_auc(fpr, tpr, fpr_max):\n",
    "    print(type(fpr))\n",
    "    partial_fpr = [fpr[i] for i in range(len(fpr)) if fpr[i] <= fpr_max]\n",
    "    partial_tpr = [tpr[i] for i in range(len(fpr)) if fpr[i] <= fpr_max]\n",
    "    partial_fpr = partial_fpr + [fpr_max]\n",
    "    partial_tpr = partial_tpr + [tpr[-1]]\n",
    "    partial_auc = (auc(partial_fpr, partial_tpr) / (fpr_max))\n",
    "    #print(partial_fpr)\n",
    "    return partial_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 5.38560965e-05 7.18081287e-05 8.97601609e-05\n",
      " 8.97601609e-05 1.61568290e-04 1.61568290e-04 1.61568290e-04\n",
      " 1.61568290e-04 1.61568290e-04 1.61568290e-04 1.79520322e-04\n",
      " 1.79520322e-04 1.97472354e-04 1.97472354e-04 1.97472354e-04\n",
      " 2.15424386e-04 2.51328450e-04 2.69280483e-04 2.87232515e-04\n",
      " 3.41088611e-04 3.59040643e-04 3.76992676e-04 3.94944708e-04\n",
      " 4.12896740e-04 4.30848772e-04 4.30848772e-04 4.30848772e-04\n",
      " 4.30848772e-04 4.84704869e-04 5.02656901e-04 5.56512997e-04\n",
      " 5.92417062e-04 6.10369094e-04 6.10369094e-04 6.28321126e-04\n",
      " 6.46273158e-04 7.36033319e-04 7.36033319e-04 7.53985351e-04\n",
      " 8.25793480e-04 8.61697544e-04 8.79649576e-04 9.51457705e-04\n",
      " 9.87361769e-04 1.00531380e-03 1.04121787e-03 1.05916990e-03\n",
      " 1.07712193e-03 1.09507396e-03 1.11302599e-03 1.13097803e-03\n",
      " 1.18483412e-03 1.20278616e-03 1.20278616e-03 1.20278616e-03\n",
      " 1.23869022e-03 1.27459428e-03 1.29254632e-03 1.29254632e-03\n",
      " 1.32845038e-03 1.38230648e-03 1.40025851e-03 1.47206664e-03\n",
      " 1.49001867e-03 1.54387477e-03 1.57977883e-03 1.61568290e-03\n",
      " 1.72339509e-03 1.75929915e-03 1.83110728e-03 1.86701135e-03\n",
      " 2.04653167e-03 2.08243573e-03 2.10038776e-03 2.13629183e-03\n",
      " 2.15424386e-03 2.22605199e-03 2.26195605e-03 2.26195605e-03\n",
      " 2.33376418e-03 2.35171621e-03 2.49533247e-03 2.49533247e-03\n",
      " 2.51328450e-03 2.56714060e-03 2.71075686e-03 2.80051702e-03\n",
      " 2.81846905e-03 2.81846905e-03 2.87232515e-03 2.87232515e-03\n",
      " 2.99798937e-03 2.99798937e-03 3.01594140e-03 3.12365360e-03\n",
      " 3.37498205e-03 3.41088611e-03 3.78787879e-03 5.06247307e-03\n",
      " 5.08042510e-03 5.33175355e-03 5.38560965e-03 6.21140313e-03\n",
      " 6.24730720e-03 7.89889415e-03 7.91684619e-03 7.95275025e-03\n",
      " 9.90952176e-03 9.94542582e-03 1.08430274e-02 1.09148356e-02\n",
      " 1.22971420e-02 1.23330461e-02 1.41462013e-02 1.41821054e-02\n",
      " 1.48283786e-02 1.48463306e-02 1.54028436e-02 1.54207956e-02\n",
      " 1.58157403e-02 1.58516444e-02 1.58875485e-02 1.66594859e-02\n",
      " 1.66774379e-02 1.73416631e-02 1.73775671e-02 1.84367370e-02\n",
      " 1.84726411e-02 1.93702427e-02 1.93881947e-02 1.94061468e-02\n",
      " 2.04294126e-02 2.17578630e-02 2.17758150e-02 2.18476232e-02\n",
      " 2.31760735e-02 2.31940256e-02 2.44327158e-02 2.44506678e-02\n",
      " 2.44506678e-02 2.44686198e-02 2.45045239e-02 2.66946718e-02\n",
      " 2.67305759e-02 2.67485279e-02 2.91720523e-02 2.91900043e-02\n",
      " 2.92438604e-02 2.92618124e-02 3.27624587e-02 3.27804107e-02\n",
      " 3.28522189e-02 3.78069798e-02 4.13973862e-02 4.14332902e-02\n",
      " 4.14512423e-02 4.15230504e-02 4.40542869e-02 4.41081430e-02\n",
      " 5.05170185e-02 5.05349706e-02 5.05529226e-02 6.13241419e-02\n",
      " 1.00000000e+00]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ROC(fpr, tpr, fpr_max=0.01, title='ROC curves'):\n",
    "    plt.figure()\n",
    "    lw = 3\n",
    "\n",
    "    plt.plot([0, 100], [100, 100], color='lightgray', lw=1, linestyle='--')\n",
    "    plt.plot([0, 100], [90, 90], color='lightgray', lw=1, linestyle='--')\n",
    "    plt.plot([0, 100], [80, 80], color='lightgray', lw=1, linestyle='--')\n",
    "    plt.plot([1.0, 1.0], [50, 105], color='lightgray', lw=1, linestyle='--')\n",
    "    plt.plot([0.5, 0.5], [50, 105], color='lightgray', lw=1, linestyle='--')\n",
    "    plt.plot([0.2, 0.2], [50, 105], color='lightgray', lw=1, linestyle='--')\n",
    "    plt.plot([0.1, 0.1], [50, 105], color='lightgray', lw=1, linestyle='--')\n",
    "\n",
    "    pauc = compute_partial_auc(fpr, tpr, fpr_max)\n",
    "    plt.plot(fpr*100, tpr*100, color='blue', lw=lw, label='AUC = %.2f, PAUC = %.4f' % (auc(fpr, tpr), pauc))\n",
    "\n",
    "    plt.xlim([0.0, fpr_max*100])\n",
    "    plt.ylim([50, 105])\n",
    "    plt.xlabel('False Positive (%)')\n",
    "    plt.ylabel('True Positives (%)')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('data/no_type-rm_missing-rm_total.pdf')\n",
    "    #plt.savefig('data/all_features.pdf')\n",
    "\n",
    "    plt.show()\n",
    "   \n",
    "    \n",
    "print(fpr)    \n",
    "plot_ROC(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
